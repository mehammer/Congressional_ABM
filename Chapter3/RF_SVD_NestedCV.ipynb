{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7DL626gu40pEjUqfluhYo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VfZNy7ZeGGAl"},"outputs":[],"source":["##import and format data\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import PCA\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","#Upload complete training dataset\n","all114 = pd.read_csv('training_data_114_final.csv', dtype=\"string\")\n","all2 = all114.astype({'nominate_dim1':'float', 'nominate_dim2': 'float'})\n","next114 = all2.dropna()\n","\n","###variable of NOMINATE values\n","y = next114.nominate_dim1\n","y1 = next114.nominate_dim2\n","\n","# OR Upload LEMMATIZED text\n","all114 = pd.read_csv('lemmatized_output.csv', dtype=\"string\")\n","docs = all114['speech']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iozZpiKEG6DR"},"outputs":[],"source":["#upload and run the custom stopword list\n","from congress_stopwords import congress\n","\n"]},{"cell_type":"code","source":["#Convert text to TF-IDF matrix and make it dense\n","\n","\n","vectorizer = TfidfVectorizer(stop_words=congress, min_df=5, max_df=0.5)\n","X_sparse = vectorizer.fit_transform(docs)\n","\n","\n","print(f\"TF-IDF shape before PCA: {X_sparse.shape}\")"],"metadata":{"id":"wAbN7VtLOkS7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DIMENSION 1"],"metadata":{"id":"uwTUnr-TMNU5"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error, make_scorer\n","\n","# data\n","X = X_sparse\n","y = y\n","\n","# --- pipeline: SVD + Random Forest ---\n","pipeline = Pipeline([\n","    ('svd', TruncatedSVD(random_state=42)),\n","    ('rf', RandomForestRegressor(random_state=42))\n","])\n","\n","# --- hyperparameter space ---\n","param_grid = {\n","    'svd__n_components': [100, 150, 200, 250, 300],\n","    'rf__n_estimators': [100, 200, 400, 800, 1000],\n","    'rf__max_depth': [10, 20, 40],\n","    'rf__min_samples_split': [2, 5],\n","}\n","\n","# --- scoring metrics ---\n","scoring = {\n","    'r2': make_scorer(r2_score),\n","    'rmse': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)),\n","    'mae': make_scorer(mean_absolute_error),\n","    'max_error': make_scorer(max_error)\n","}\n","\n","# --- Define outer and inner CV loops ---\n","outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# --- Storage for results ---\n","outer_results = []\n","\n","# --- Outer loop ---\n","for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n","    print(f\"\\n=== Outer Fold {fold+1} ===\")\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # --- Inner loop: hyperparameter tuning ---\n","    random_search = RandomizedSearchCV(\n","        estimator=pipeline,\n","        param_distributions=param_grid,\n","        n_iter=30,  # number of random combinations\n","        scoring='r2',\n","        cv=inner_cv,\n","        n_jobs=-1,\n","        random_state=42,\n","        verbose=1\n","    )\n","    random_search.fit(X_train, y_train)\n","\n","    # --- Get best model from inner CV ---\n","    best_model = random_search.best_estimator_\n","    print(\"Best params:\", random_search.best_params_)\n","\n","    # --- Evaluate on outer test set ---\n","    y_pred = best_model.predict(X_test)\n","    r2 = r2_score(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    max_err = max_error(y_test, y_pred)\n","\n","    outer_results.append({'fold': fold+1, 'r2': r2, 'rmse': rmse, 'mae': mae, 'max_error': max_err})\n","\n","# --- Summary of outer results ---\n","print(\"\\n=== Nested Cross-Validation Results ===\")\n","for res in outer_results:\n","    print(f\"Fold {res['fold']}: R2={res['r2']:.4f}, RMSE={res['rmse']:.4f}, MAE={res['mae']:.4f}, MaxErr={res['max_error']:.4f}\")\n","\n","mean_r2 = np.mean([r['r2'] for r in outer_results])\n","\n"],"metadata":{"id":"Jig502n7jOVE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DIMENSION 2"],"metadata":{"id":"NsOC6NodMLXb"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error, make_scorer\n","\n","# --- data ---\n","X = X_sparse\n","y = y1\n","\n","# --- pipeline: SVD + Random Forest ---\n","pipeline = Pipeline([\n","    ('svd', TruncatedSVD(random_state=42)),\n","    ('rf', RandomForestRegressor(random_state=42))\n","])\n","\n","# --- hyperparameter space ---\n","param_grid = {\n","    'svd__n_components': [100, 150, 200, 250, 300],\n","    'rf__n_estimators': [100, 200, 400, 800, 1000],\n","    'rf__max_depth': [10, 20, 40],\n","    'rf__min_samples_split': [2, 5],\n","}\n","\n","# --- scoring metrics ---\n","scoring = {\n","    'r2': make_scorer(r2_score),\n","    'rmse': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred)),\n","    'mae': make_scorer(mean_absolute_error),\n","    'max_error': make_scorer(max_error)\n","}\n","\n","# --- Define outer and inner CV loops ---\n","outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n","\n","# --- Storage for results ---\n","outer_results = []\n","\n","# --- Outer loop ---\n","for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n","    print(f\"\\n=== Outer Fold {fold+1} ===\")\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # --- Inner loop: hyperparameter tuning ---\n","    random_search = RandomizedSearchCV(\n","        estimator=pipeline,\n","        param_distributions=param_grid,\n","        n_iter=30,  # number of random combinations\n","        scoring='r2',\n","        cv=inner_cv,\n","        n_jobs=-1,\n","        random_state=42,\n","        verbose=1\n","    )\n","    random_search.fit(X_train, y_train)\n","\n","    # --- Get best model from inner CV ---\n","    best_model = random_search.best_estimator_\n","    print(\"Best params:\", random_search.best_params_)\n","\n","    # --- Evaluate on outer test set ---\n","    y_pred = best_model.predict(X_test)\n","    r2 = r2_score(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    max_err = max_error(y_test, y_pred)\n","\n","    outer_results.append({'fold': fold+1, 'r2': r2, 'rmse': rmse, 'mae': mae, 'max_error': max_err})\n"],"metadata":{"id":"PvtaxrdPMKC7"},"execution_count":null,"outputs":[]}]}