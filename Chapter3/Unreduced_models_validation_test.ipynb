{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHSMLZEC1qhWy6fpAoXJpM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VfZNy7ZeGGAl"},"outputs":[],"source":["##import and format data\n","import pandas as pd\n","import numpy as np\n","\n","#Upload complete training dataset\n","all114 = pd.read_csv('training_data_114_final.csv',dtype='string')\n","all2 = all114.astype({'speech':'string','nominate_dim1':'float', 'nominate_dim2': 'float'})\n","final114 = all2.dropna()\n","\n","# OR Upload LEMMATIZED dataset\n","all114 = pd.read_csv('lemmatized_output.csv', dtype=\"string\")\n","docs = all114['speech']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iozZpiKEG6DR"},"outputs":[],"source":["#upload the custom stopword list\n","from congress_stopwords import congress\n"]},{"cell_type":"code","source":["final114.speech.str.len()\n","#Just making sure that no speech data were truncated during preprocessing\n","#and that the proper number of documents are present."],"metadata":{"id":"emwjBiW8NfsT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"htuvfc61xQfE"},"outputs":[],"source":["####create the TF-IDF matrix\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer(\n","        sublinear_tf=True, max_df=0.5, min_df=5, stop_words=congress\n","    )\n","train2 = vectorizer.fit_transform(docs) #fit the lemmatized text\n"]},{"cell_type":"code","source":["X = train2\n","###variables of NOMINATE values\n","y = final114.nominate_dim1\n","y1 = final114.nominate_dim2"],"metadata":{"id":"0ICneSx2ctgS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FEATURE OVERVIEW"],"metadata":{"id":"wAAw9SyFcP7H"}},{"cell_type":"code","source":["tfidf = TfidfVectorizer()\n","\n","###tf-idf in matrix form (from g4g)\n","print('\\nWord indexes:')\n","print(tfidf.vocabulary)\n","\n","# display tf-idf values\n","print('\\ntf-idf value:')\n","print(X)\n","\n","# in matrix form\n","print('\\ntf-idf values in matrix form:')\n","print(X.toarray())"],"metadata":{"id":"-twKr9TqIl1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"id":"PvQdtXu5Iuut"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["IMPORT VALIDATION DATA"],"metadata":{"id":"nB7yKlC9IvoG"}},{"cell_type":"code","source":["###116th CONGRESSIONAL RECORD speeches\n","all116 = pd.read_csv('116incCR1.txt', dtype=\"string\", sep = ',')\n","all2 = all116.astype({'score':'float','dim2':'float'})\n","cr116_1 = all2.dropna()\n","val_speech = cr116_1['text']"],"metadata":{"id":"ErOfJwyXdccp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cr116_1.text.str.len()"],"metadata":{"id":"DuzOjKG1e3gY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = val_speech\n","\n","import spacy\n","\n","# Load the English language model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Function to lemmatize a single text entry\n","def lemmatize_text(text):\n","    text = str(text)\n","    if len(text) > 1_000_000:\n","        return \"TEXT TOO LONG\"\n","    doc = nlp(text)  # Ensure text is string\n","    return \" \".join([token.lemma_ for token in doc])\n","\n","# Apply to the whole column\n","val_speeches = doc.apply(lemmatize_text)\n","\n","# Preview result\n","print(val_speeches.head())"],"metadata":{"id":"LjzYp3EBNZmd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_val = vectorizer.transform(val_speeches)\n","y_val = cr116_1.score\n","y_val1 = cr116_1.dim2"],"metadata":{"id":"8v2svcd8g4qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_val.shape"],"metadata":{"id":"fCutIp_jY6sL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####116 CR VALIDATION - DIMENSION 1\n","\n","import numpy as np\n","from sklearn.linear_model import Ridge, Lasso, SGDRegressor, LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error\n","from scipy.stats import uniform, loguniform\n","\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(alpha=0.05589),\n","    'Lasso Regression': Lasso(max_iter=5000, alpha=0.000498),\n","    'SGD Regressor (squared_epsilon_insensitive)': SGDRegressor(\n","        loss='squared_epsilon_insensitive',\n","        max_iter=2000,\n","        random_state=42,\n","        alpha=0.000366,\n","        penalty='l2',\n","        epsilon=0.0374,\n","        learning_rate='adaptive'\n","    )\n","}\n","\n","for name, model in models.items():\n","    print(f\"Training {name}...\")\n","    model.fit(X, y)\n","\n","# Assuming best_models are already trained on full training data,\n","# X_unseen is the unseen feature data, and y_val is the ground truth labels.\n","\n","print(\"Performance on unseen validation data:\\n\")\n","\n","for name, model in models.items():\n","    # Predict on unseen data\n","    y_pred = model.predict(X_val)\n","\n","    # Calculate metrics\n","    r2 = r2_score(y_val, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n","    mae = mean_absolute_error(y_val, y_pred)\n","    max_err = max_error(y_val, y_pred)\n","\n","    # Display results\n","    print(f\"{name}:\")\n","    print(f\"  R2 Score: {r2:.4f}\")\n","    print(f\"  RMSE: {rmse:.4f}\")\n","    print(f\"  MAE: {mae:.4f}\")\n","    print(f\"  Max Error: {max_err:.4f}\\n\")\n","\n","\n"],"metadata":{"id":"wlnKDdquXMBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###116CR - DIMENSION 2\n","\n","\n","import numpy as np\n","from sklearn.linear_model import Ridge, Lasso, SGDRegressor, LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error\n","from scipy.stats import uniform, loguniform\n","\n","\n","models1 = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(alpha=0.3905),\n","    'Lasso Regression': Lasso(max_iter=5000, alpha=0.000498),\n","    'SGD Regressor (squared_epsilon_insensitive)': SGDRegressor(\n","        loss='squared_epsilon_insensitive',\n","        max_iter=2000,\n","        random_state=42,\n","        alpha=0.000366,\n","        penalty='l2',\n","        epsilon=0.0374,\n","        learning_rate='adaptive'\n","    )\n","}\n","\n","for name, model in models1.items():\n","    print(f\"Training {name}...\")\n","    model.fit(X, y1)\n","\n","\n","\n","# Assuming best_models are already trained on full training data,\n","# X_unseen is the unseen feature data, and y_val is the ground truth labels.\n","\n","print(\"Performance on unseen validation data:\\n\")\n","\n","for name, model in models1.items():\n","    # Predict on unseen data\n","    y_pred1 = model.predict(X_val)\n","\n","    # Calculate metrics\n","    r2 = r2_score(y_val1, y_pred1)\n","    rmse = np.sqrt(mean_squared_error(y_val1, y_pred1))\n","    mae = mean_absolute_error(y_val1, y_pred1)\n","    max_err = max_error(y_val1, y_pred1)\n","\n","    # Display results\n","    print(f\"{name}:\")\n","    print(f\"  R2 Score: {r2:.4f}\")\n","    print(f\"  RMSE: {rmse:.4f}\")\n","    print(f\"  MAE: {mae:.4f}\")\n","    print(f\"  Max Error: {max_err:.4f}\\n\")\n","\n","\n"],"metadata":{"id":"XlMuuiQOaM0Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["PREDICTION OF CANDIDATE VALUES"],"metadata":{"id":"urgxFS3hzDRV"}},{"cell_type":"code","source":["all116 = pd.read_csv('116cand.csv', dtype=\"string\", sep = ',')\n","cand116 = all116.dropna()\n","cand_speech = cand116['text']"],"metadata":{"id":"evTTLsmuzZpj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = cand_speech\n","\n","import spacy\n","\n","# Load the English language model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Function to lemmatize a single text entry\n","def lemmatize_text(text):\n","    text = str(text)\n","    if len(text) > 1_000_000:\n","        return \"TEXT TOO LONG\"\n","    doc = nlp(text)  # Ensure text is string\n","    return \" \".join([token.lemma_ for token in doc])\n","\n","# Apply to the whole column\n","cand_speeches = doc.apply(lemmatize_text)\n","\n","# Preview result\n","print(cand_speeches.head())"],"metadata":{"id":"f-wx_P6nQagX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_cand = vectorizer.transform(cand_speeches)\n"],"metadata":{"id":"LKHXQlXYBGGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit best models on full training data -- DIMENSION 1\n","for name, model in models.items():\n","    print(f\"Training {name} on full training dataset...\")\n","    model.fit(X, y)  # refit best model on full training data\n","\n","# Now apply to unseen data and get predictions\n","predictions = {}\n","for name, model in models.items():\n","    print(f\"Predicting with {name} on unseen data...\")\n","    preds = model.predict(X_cand)\n","    predictions[name] = preds\n","\n","\n"],"metadata":{"id":"OwbVNpQWYJ6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(predictions)"],"metadata":{"id":"QQwvucwEZg4h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DIMENSION 2"],"metadata":{"id":"pqag9KvUZX5T"}},{"cell_type":"code","source":["####PREDICT CHALLENGER SCORES -- DIMENSION 2\n","\n","import numpy as np\n","from sklearn.linear_model import Ridge, Lasso, SGDRegressor, LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error\n","from scipy.stats import uniform, loguniform\n","\n","\n","models1 = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(alpha=0.3905),\n","    'Lasso Regression': Lasso(max_iter=5000, alpha=0.000498),\n","    'SGD Regressor (squared_epsilon_insensitive)': SGDRegressor(\n","        loss='squared_epsilon_insensitive',\n","        max_iter=2000,\n","        random_state=42,\n","        alpha=0.000366,\n","        penalty='l2',\n","        epsilon=0.0374,\n","        learning_rate='adaptive'\n","    )\n","}\n","\n","for name, model in models1.items():\n","    print(f\"Training {name} on full training dataset...\")\n","    model.fit(X, y1)  # refit best model on full training data\n","\n","# Now apply to unseen data and get predictions\n","predictions1 = {}\n","for name, model in models1.items():\n","    print(f\"Predicting with {name} on unseen data...\")\n","    preds = model.predict(X_cand)\n","    predictions1[name] = preds\n","\n","\n"],"metadata":{"id":"y-Z7vUO6cdWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(predictions1)"],"metadata":{"id":"_SmgB65qcnWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FEATURE EXTRACTION - DIMENSION 1"],"metadata":{"id":"h-wFn-fqg3vV"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge, Lasso, SGDRegressor, LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error\n","\n","feature_names = np.array(vectorizer.get_feature_names_out())\n","\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(alpha=0.05589),\n","    'Lasso Regression': Lasso(max_iter=5000, alpha=0.000498),\n","    'SGD Regressor (squared_epsilon_insensitive)': SGDRegressor(\n","        loss='squared_epsilon_insensitive',\n","        max_iter=2000,\n","        random_state=42,\n","        alpha=0.000366,\n","        penalty='l2',\n","        epsilon=0.0374,\n","        learning_rate='adaptive'\n","    )\n","}\n","\n","for name, model in models.items():\n","    print(f\"Training {name}...\")\n","    model.fit(X, y)\n","    coefs = model.coef_\n","\n","    # Sort coefficients\n","    sorted_idx = np.argsort(coefs)\n","    top_neg_idx = sorted_idx[:20]   # 5 most negative\n","    top_pos_idx = sorted_idx[-20:]  # 5 most positive\n","\n","    print(f\"\\n=== {name} ===\")\n","    print(\"Top positive words (increase Dim 1 score):\")\n","    for i in top_pos_idx[::-1]:\n","        print(f\"  {feature_names[i]:<15} {coefs[i]:.4f}\")\n","\n","    print(\"Top negative words (decrease Dim 1 score):\")\n","    for i in top_neg_idx:\n","        print(f\"  {feature_names[i]:<15} {coefs[i]:.4f}\")\n","\n","\n","\n"],"metadata":{"id":"RL8KxCmTgYF9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FEATURE EXTRACTION - DIMENSION 2"],"metadata":{"id":"2JOXC2hl0Cmk"}},{"cell_type":"code","source":["####FEATURE EXTRACTION -- DIMENSION 2\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge, Lasso, SGDRegressor, LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, max_error\n","\n","feature_names = np.array(vectorizer.get_feature_names_out())\n","\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(alpha=0.05589),\n","    'Lasso Regression': Lasso(max_iter=5000, alpha=0.000498),\n","    'SGD Regressor (squared_epsilon_insensitive)': SGDRegressor(\n","        loss='squared_epsilon_insensitive',\n","        max_iter=2000,\n","        random_state=42,\n","        alpha=0.000366,\n","        penalty='l2',\n","        epsilon=0.0374,\n","        learning_rate='adaptive'\n","    )\n","}\n","\n","for name, model in models.items():\n","    print(f\"Training {name}...\")\n","    model.fit(X, y1)\n","    coefs = model.coef_\n","\n","    # Sort coefficients\n","    sorted_idx = np.argsort(coefs)\n","    top_neg_idx = sorted_idx[:20]   # 5 most negative\n","    top_pos_idx = sorted_idx[-20:]  # 5 most positive\n","\n","    print(f\"\\n=== {name} ===\")\n","    print(\"Top positive words (increase Dim 1 score):\")\n","    for i in top_pos_idx[::-1]:\n","        print(f\"  {feature_names[i]:<15} {coefs[i]:.4f}\")\n","\n","    print(\"Top negative words (decrease Dim 1 score):\")\n","    for i in top_neg_idx:\n","        print(f\"  {feature_names[i]:<15} {coefs[i]:.4f}\")\n","\n","\n","\n"],"metadata":{"id":"r3m2iiosmEpK"},"execution_count":null,"outputs":[]}]}