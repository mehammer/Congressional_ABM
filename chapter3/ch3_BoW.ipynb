{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMVleCgVIwkvRTjrtfDp537"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["3/8/25: Updated from the last stable/functional version (\"dim1_BOW_train-test-combined\").  Two major additions:  A different cross-validation method that does not require using **negative** mean absolute error.  I have also updated and expanded the \"newsroom\" test dataset in the hope of resolving the negative R2 issue.\n","\n","7/14/25: implements the following changes from HK: BoW for transforming"],"metadata":{"id":"roHAooeV_MoE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfZNy7ZeGGAl"},"outputs":[],"source":["##import and format data\n","import pandas as pd\n","import numpy as np\n","\n","#Upload complete training dataset\n","all114 = pd.read_csv('training_data_114_final.csv',dtype='string')\n","all2 = all114.astype({'speech':'string','nominate_dim1':'float', 'nominate_dim2': 'float'})\n","final114 = all2.dropna()\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"wAAw9SyFcP7H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iozZpiKEG6DR"},"outputs":[],"source":["#upload the custom stopword list\n","from congress_stopwords import congress\n"]},{"cell_type":"code","source":["final114.speech.str.len()\n","#Just making sure that no speech data were truncated during preprocessing\n","#and that the proper number of documents are present."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"emwjBiW8NfsT","executionInfo":{"status":"ok","timestamp":1752543765210,"user_tz":240,"elapsed":136,"user":{"displayName":"Michael Hammer","userId":"02778246655929855865"}},"outputId":"e6f841c6-33b0-4f20-b1f6-4277d386d48c","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       17784\n","1       25356\n","2      113985\n","3      109704\n","4       45340\n","        ...  \n","433     90749\n","434     31889\n","435     15301\n","436     24527\n","437      9209\n","Name: speech, Length: 438, dtype: Int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>speech</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17784</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25356</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>113985</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>109704</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45340</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>90749</td>\n","    </tr>\n","    <tr>\n","      <th>434</th>\n","      <td>31889</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>15301</td>\n","    </tr>\n","    <tr>\n","      <th>436</th>\n","      <td>24527</td>\n","    </tr>\n","    <tr>\n","      <th>437</th>\n","      <td>9209</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>438 rows Ã— 1 columns</p>\n","</div><br><label><b>dtype:</b> Int64</label>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["NOTE: I TRIED THE VECTORIZER WITH AND WITHOUT LEMMATIZING."],"metadata":{"id":"_gqgOu2FOuYA"}},{"cell_type":"code","source":["###lemmatize prior to vectorizer\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","\n","W = []\n","lemmatizer = WordNetLemmatizer()\n","for i in final114.speech:\n","  lems = lemmatizer.lemmatize(i)\n","  W.append(lems)\n","\n"],"metadata":{"id":"JSADqY7Wdkeq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752543780840,"user_tz":240,"elapsed":94,"user":{"displayName":"Michael Hammer","userId":"02778246655929855865"}},"outputId":"bc743273-a056-4d0d-edf5-43b911b3de5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["BAG OF WORDS PREPROCESSING"],"metadata":{"id":"9e0HY7i2KpGJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"htuvfc61xQfE"},"outputs":[],"source":["####create the BoW vectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer = CountVectorizer(\n","       stop_words=congress\n","    )\n","#train2 = vectorizer.fit_transform(W)\n","train1 = vectorizer.fit_transform(final114.speech)"]},{"cell_type":"code","source":["X = train1\n","###variable of NOMINATE values\n","y = final114.nominate_dim1\n","y1 = final114.nominate_dim2"],"metadata":{"id":"0ICneSx2ctgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RepeatedKFold, cross_val_score, cross_val_predict\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split, RepeatedKFold\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, max_error\n"],"metadata":{"id":"BwkU8QBTT1po"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TRAINING AND CROSS-VALIDATION -- DIMENSION 1\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    #'Random Forest Regressor': RandomForestRegressor(n_estimators=600),\n","    #'Gradient Boosting Regressor': GradientBoostingRegressor(n_estimators=1600)\n","}\n","\n","# Create a RepeatedKFold cross-validator\n","rkf = RepeatedKFold(n_splits=4, n_repeats=1, random_state=42)\n","\n","# Function to calculate all metrics\n","def calculate_metrics(model, X, y, cv):\n","    r2_scores = []\n","    rmse_scores = []\n","    mae_scores = []\n","    max_errors = []\n","\n","    for train_index, test_index in cv.split(X):\n","        X_train, X_test = X[train_index], X[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate metrics\n","        r2_scores.append(r2_score(y_test, y_pred))\n","        rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n","        mae_scores.append(mean_absolute_error(y_test, y_pred))\n","        max_errors.append(max_error(y_test, y_pred))\n","\n","    return r2_scores, rmse_scores, mae_scores, max_errors\n","\n","# Evaluate each model using cross-validation and calculate the metrics\n","for model_name, model in models.items():\n","    r2_scores, rmse_scores, mae_scores, max_errors = calculate_metrics(model, X, y, rkf)\n","\n","    #print(f\"{model_name} - R2 Scores: {r2_scores}\")\n","    print(f\"{model_name} - Mean R2: {np.mean(r2_scores)}\")\n","    #print(f\"{model_name} - RMSE Scores: {rmse_scores}\")\n","    print(f\"{model_name} - Mean RMSE: {np.mean(rmse_scores)}\")\n","    #print(f\"{model_name} - MAE Scores: {mae_scores}\")\n","    print(f\"{model_name} - Mean MAE: {np.mean(mae_scores)}\")\n","    #print(f\"{model_name} - Max Errors: {max_errors}\")\n","    print(f\"{model_name} - Mean Max Error: {np.mean(max_errors)}\\n\")\n"],"metadata":{"id":"ozYbeMjBO0cp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752590368413,"user_tz":240,"elapsed":9284,"user":{"displayName":"Michael Hammer","userId":"02778246655929855865"}},"outputId":"9cfe6c87-e772-4fec-9161-1f2f70990cae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression - Mean R2: -2.228910147036488\n","Linear Regression - Mean RMSE: 0.8008730164016948\n","Linear Regression - Mean MAE: 0.5534039123848676\n","Linear Regression - Mean Max Error: 3.943388847785059\n","\n"]}]}]}